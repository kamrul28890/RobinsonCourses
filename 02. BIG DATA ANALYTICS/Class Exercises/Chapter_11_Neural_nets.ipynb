{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIxaM43ghgf0"
      },
      "source": [
        "# Chapter 11: Neural nets\n",
        "\n",
        "> (c) 2019 Galit Shmueli, Peter C. Bruce, Peter Gedeck\n",
        ">\n",
        "> Code included in\n",
        ">\n",
        "> _Data Mining for Business Analytics: Concepts, Techniques, and Applications in Python_ (First Edition)\n",
        "> Galit Shmueli, Peter C. Bruce, Peter Gedeck, and Nitin R. Patel. 2019.\n",
        "\n",
        "## Import required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSUd1Vjehgf2"
      },
      "source": [
        "Make sure DMBA package is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:38.296244Z",
          "iopub.status.busy": "2023-06-26T14:18:38.295879Z",
          "iopub.status.idle": "2023-06-26T14:18:39.856460Z",
          "shell.execute_reply": "2023-06-26T14:18:39.855245Z"
        },
        "id": "2yxK2AC7hgf2",
        "outputId": "a711dd0f-5d59-4396-ec31-2f644096c0c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dmba\n",
            "  Downloading dmba-0.2.4-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from dmba) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from dmba) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dmba) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dmba) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from dmba) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dmba) (1.11.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dmba) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dmba) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dmba) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dmba) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->dmba) (1.16.0)\n",
            "Installing collected packages: dmba\n",
            "Successfully installed dmba-0.2.4\n"
          ]
        }
      ],
      "source": [
        "pip install dmba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:39.860624Z",
          "iopub.status.busy": "2023-06-26T14:18:39.860303Z",
          "iopub.status.idle": "2023-06-26T14:18:40.961472Z",
          "shell.execute_reply": "2023-06-26T14:18:40.960447Z"
        },
        "id": "he23bN1Qhgf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a714a5b1-5631-4cf2-e415-9bb2a2ada492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab environment detected.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import dmba\n",
        "from dmba import classificationSummary\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr0FJVbYhgf3"
      },
      "source": [
        "## Table 11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:40.964549Z",
          "iopub.status.busy": "2023-06-26T14:18:40.964006Z",
          "iopub.status.idle": "2023-06-26T14:18:40.992787Z",
          "shell.execute_reply": "2023-06-26T14:18:40.991856Z"
        },
        "id": "NZq7ld4Thgf4",
        "outputId": "a9526a09-a4ae-43a4-e2a8-c3e141f6eb93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercepts\n",
            "[array([0.13368042, 4.07247549, 7.00768105]), array([14.3074867])]\n",
            "Weights\n",
            "[array([[ -1.3065648 ,  -4.20427797, -13.29587331],\n",
            "       [ -0.04399729,  -4.91606921,  -6.03356987]]), array([[ -0.27348314],\n",
            "       [ -9.01211576],\n",
            "       [-17.63504684]])]\n",
            "   Obs.  Fat  Salt Acceptance   dislike      like\n",
            "0     1  0.2   0.9       like  0.000490  0.999510\n",
            "1     2  0.1   0.1    dislike  0.999994  0.000006\n",
            "2     3  0.2   0.4    dislike  0.999741  0.000259\n",
            "3     4  0.2   0.5    dislike  0.997368  0.002632\n",
            "4     5  0.4   0.5       like  0.002133  0.997867\n",
            "5     6  0.3   0.8       like  0.000075  0.999925\n"
          ]
        }
      ],
      "source": [
        "example_df = dmba.load_data('TinyData.csv') #load the data\n",
        "\n",
        "predictors = ['Fat', 'Salt'] #determine preditors\n",
        "outcome = 'Acceptance' #determine the outcome\n",
        "\n",
        "X = example_df[predictors] #put preditors in a variable named X\n",
        "y = example_df[outcome] #put the outcome in a variable named y\n",
        "classes = sorted(y.unique()) #get the unique values of y and sort them and put them in a variable named classes\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[3], activation='logistic', solver='lbfgs', random_state=1) #define the NN model with activation function of logistic\n",
        "clf.fit(X, y) #run the model\n",
        "clf.predict(X) # make a prediction\n",
        "\n",
        "# Network structure\n",
        "print('Intercepts')\n",
        "print(clf.intercepts_)\n",
        "\n",
        "print('Weights')\n",
        "print(clf.coefs_)\n",
        "\n",
        "# Prediction\n",
        "print(pd.concat([\n",
        "    example_df,\n",
        "    pd.DataFrame(clf.predict_proba(X), columns=classes)\n",
        "], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G08hhyYihgf4"
      },
      "source": [
        "## Table 11.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:41.003943Z",
          "iopub.status.busy": "2023-06-26T14:18:41.003681Z",
          "iopub.status.idle": "2023-06-26T14:18:41.011873Z",
          "shell.execute_reply": "2023-06-26T14:18:41.011002Z"
        },
        "id": "mZgYIrChhgf4",
        "outputId": "6ae1c874-0b83-47c9-c43b-f7d928c791ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Accuracy 1.0000)\n",
            "\n",
            "        Prediction\n",
            " Actual dislike    like\n",
            "dislike       3       0\n",
            "   like       0       3\n"
          ]
        }
      ],
      "source": [
        "classificationSummary(y, clf.predict(X), class_names=classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2d8n9V2hgf5"
      },
      "source": [
        "## Table 11.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:41.015075Z",
          "iopub.status.busy": "2023-06-26T14:18:41.014387Z",
          "iopub.status.idle": "2023-06-26T14:18:41.087665Z",
          "shell.execute_reply": "2023-06-26T14:18:41.086742Z"
        },
        "id": "SSQJStEAhgf5",
        "outputId": "cc8bda23-152b-4ed0-ace3-6349fb4067df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Accuracy 0.8550)\n",
            "\n",
            "       Prediction\n",
            "Actual   0   1   2\n",
            "     0 218   0   1\n",
            "     1   0 119   0\n",
            "     2  24  33   5\n"
          ]
        }
      ],
      "source": [
        "accidents_df = dmba.load_data('accidentsnn.csv')\n",
        "input_vars = ['ALCHL_I', 'PROFIL_I_R', 'VEH_INVL']\n",
        "\n",
        "accidents_df.SUR_COND = accidents_df.SUR_COND.astype('category')\n",
        "accidents_df.MAX_SEV_IR = accidents_df.MAX_SEV_IR.astype('category')\n",
        "\n",
        "# convert the categorical data into dummy variables\n",
        "# exclude the column for SUR_COND 9 = unknown\n",
        "processed = pd.get_dummies(accidents_df, columns=['SUR_COND']).drop(columns=['SUR_COND_9'])\n",
        "\n",
        "outcome = 'MAX_SEV_IR'\n",
        "predictors = [c for c in processed.columns if c != outcome]\n",
        "\n",
        "# partition data\n",
        "X = processed[predictors]\n",
        "y = processed[outcome]\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "\n",
        "# train neural network with 2 hidden nodes\n",
        "clf = MLPClassifier(hidden_layer_sizes=[2], activation='logistic', solver='lbfgs',\n",
        "                    random_state=1)\n",
        "clf.fit(train_X, train_y.values)\n",
        "\n",
        "# validation performance\n",
        "classificationSummary(valid_y, clf.predict(valid_X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_FztHPIhgf5"
      },
      "source": [
        "## Fitting class probabilities separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-26T14:18:41.090116Z",
          "iopub.status.busy": "2023-06-26T14:18:41.089859Z",
          "iopub.status.idle": "2023-06-26T14:18:41.214858Z",
          "shell.execute_reply": "2023-06-26T14:18:41.213976Z"
        },
        "id": "xdV-3rkFhgf5",
        "outputId": "f6808692-1480-429e-ac96-e46f578bffe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix (Accuracy 0.8731)\n",
            "\n",
            "             Prediction\n",
            "      Actual MAX_SEV_IR_0 MAX_SEV_IR_1 MAX_SEV_IR_2\n",
            "MAX_SEV_IR_0          332            0            0\n",
            "MAX_SEV_IR_1            0          170           10\n",
            "MAX_SEV_IR_2           31           35           21\n",
            "Confusion Matrix (Accuracy 0.8675)\n",
            "\n",
            "             Prediction\n",
            "      Actual MAX_SEV_IR_0 MAX_SEV_IR_1 MAX_SEV_IR_2\n",
            "MAX_SEV_IR_0          218            0            1\n",
            "MAX_SEV_IR_1            0          113            6\n",
            "MAX_SEV_IR_2           24           22           16\n"
          ]
        }
      ],
      "source": [
        "accidents_df = dmba.load_data('accidentsnn.csv')\n",
        "input_vars = ['ALCHL_I', 'PROFIL_I_R', 'VEH_INVL']\n",
        "\n",
        "accidents_df.SUR_COND = accidents_df.SUR_COND.astype('category')\n",
        "accidents_df.MAX_SEV_IR = accidents_df.MAX_SEV_IR.astype('category')\n",
        "\n",
        "# convert the categorical data into dummy variables\n",
        "processed = pd.get_dummies(accidents_df)\n",
        "# drop the column for SUR_COND 9 = unknown\n",
        "processed = processed.drop(columns=['SUR_COND_9'])\n",
        "\n",
        "outcome = ['MAX_SEV_IR_0', 'MAX_SEV_IR_1', 'MAX_SEV_IR_2']\n",
        "predictors = [c for c in processed.columns if c not in outcome]\n",
        "classes = sorted(outcome)\n",
        "\n",
        "# partition data\n",
        "X = processed[predictors]\n",
        "y = processed[outcome]\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "\n",
        "# train neural network with 2 hidden nodes\n",
        "clf = MLPClassifier(hidden_layer_sizes=[2], activation='logistic', solver='lbfgs',\n",
        "                    random_state=1, max_iter=500)\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# validation performance\n",
        "validPrediction = pd.DataFrame(clf.predict(valid_X), columns=outcome).idxmax(axis=1)\n",
        "classificationSummary(valid_y.idxmax(axis=1), validPrediction, class_names=classes)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}